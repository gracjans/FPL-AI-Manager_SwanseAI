{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate models predictions (each model trained on different data - separated by players positions)\n",
    "### Select best predicted squad and compare gained points with average points from specific gameweek"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from src.data.data_loader import load_average_pts\n",
    "from src.features.data_engineering import preprocess_seasons_data\n",
    "from src.features.data_engineering import reverse_processing\n",
    "\n",
    "from src.modeling.train_model import train_mlp_model\n",
    "from src.modeling.predictions import merge_reversed_data_with_predictions\n",
    "from src.modeling.evaluate_squad import squad_selection_without_constraints\n",
    "from src.modeling.evaluate_squad import get_average_pts\n",
    "from src.modeling.evaluate_squad import evaluate_selected_squad_without_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "average_pts = load_average_pts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   GW  AVG_PTS_2016/17  AVG_PTS_2018/19  AVG_PTS_2021/22\n0   1               44               53               69\n1   2               56               59               56\n2   3               40               48               54\n3   4               41               43               57\n4   5               47               46               55",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GW</th>\n      <th>AVG_PTS_2016/17</th>\n      <th>AVG_PTS_2018/19</th>\n      <th>AVG_PTS_2021/22</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>44</td>\n      <td>53</td>\n      <td>69</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>56</td>\n      <td>59</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>40</td>\n      <td>48</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>41</td>\n      <td>43</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>47</td>\n      <td>46</td>\n      <td>55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_pts.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load data by position\n",
    "data_intermediate_path = os.path.dirname(os.getcwd()) + '\\\\data\\\\intermediate\\\\'\n",
    "\n",
    "data_gk = pd.read_csv(data_intermediate_path + 'separate/gk.csv')\n",
    "data_def = pd.read_csv(data_intermediate_path + 'separate/def.csv')\n",
    "data_mid = pd.read_csv(data_intermediate_path + 'separate/mid.csv')\n",
    "data_fwd = pd.read_csv(data_intermediate_path + 'separate/fwd.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate models trained on merged seasons data with historical rolling features and with data about next game opponent team"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "rolling_columns_gk = ['bonus', 'bps', 'clean_sheets', 'goals_conceded', 'influence', 'minutes',\n",
    "                      'penalties_saved', 'saves', 'selected', 'player_team_score', 'opponent_team_score',\n",
    "                      'total_points', 'transfers_in', 'transfers_out','value']\n",
    "\n",
    "rolling_columns_def = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity', 'goals_conceded', 'goals_scored',\n",
    "                       'ict_index', 'influence', 'minutes', 'selected', 'player_team_score', 'opponent_team_score',\n",
    "                       'threat', 'total_points', 'transfers_in', 'transfers_out', 'value', 'yellow_cards']\n",
    "\n",
    "rolling_columns_mid = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity', 'goals_conceded', 'goals_scored',\n",
    "                       'ict_index', 'influence', 'minutes', 'selected', 'player_team_score', 'opponent_team_score',\n",
    "                       'threat', 'total_points', 'transfers_in', 'transfers_out', 'value', 'yellow_cards']\n",
    "\n",
    "rolling_columns_fwd = ['assists', 'bonus', 'bps', 'creativity', 'goals_scored', 'ict_index', 'influence',\n",
    "                       'minutes', 'selected', 'player_team_score', 'opponent_team_score', 'threat',\n",
    "                       'total_points', 'transfers_in', 'transfers_out', 'value', 'yellow_cards']\n",
    "\n",
    "times = ['all', 6, 3]\n",
    "\n",
    "test_subset_XL = (['2016-17', [4, 8, 9, 14, 18, 20, 21, 26, 32]], ['2018-19', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], ['2021-22', [17, 18, 19, 20, 21, 22, 23, 24, 25, 26]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "(x_train_gk, y_train_gk), (x_test_gk, y_test_gk), (x_train_target_gk, x_test_target_gk), x_scaler_gk = preprocess_seasons_data(data_gk, random_split=False, test_subset=test_subset_XL, rolling_features=True, rolling_columns=rolling_columns_gk, rolling_times=times, opponent_team_stats=True)\n",
    "\n",
    "(x_train_def, y_train_def), (x_test_def, y_test_def), (x_train_target_def, x_test_target_def), x_scaler_def = preprocess_seasons_data(data_def, random_split=False, test_subset=test_subset_XL, rolling_features=True, rolling_columns=rolling_columns_def, rolling_times=times, opponent_team_stats=True)\n",
    "\n",
    "(x_train_mid, y_train_mid), (x_test_mid, y_test_mid), (x_train_target_mid, x_test_target_mid), x_scaler_mid = preprocess_seasons_data(data_mid, random_split=False, test_subset=test_subset_XL, rolling_features=True, rolling_columns=rolling_columns_mid, rolling_times=times, opponent_team_stats=True)\n",
    "\n",
    "(x_train_fwd, y_train_fwd), (x_test_fwd, y_test_fwd), (x_train_target_fwd, x_test_target_fwd), x_scaler_fwd = preprocess_seasons_data(data_fwd, random_split=False, test_subset=test_subset_XL, rolling_features=True, rolling_columns=rolling_columns_fwd, rolling_times=times, opponent_team_stats=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train_baseline_mlp(x_train, y_train, x_test, x_scaler, x_test_target):\n",
    "    model_mlp = tf.keras.models.Sequential()\n",
    "\n",
    "    model_mlp.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "\n",
    "    if len(x_train) > 50000:\n",
    "        model_mlp.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "\n",
    "    model_mlp.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "    model_mlp.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "    model_mlp.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    history = model_mlp.fit(x_train, y_train,\n",
    "                            batch_size=16,\n",
    "                            epochs=20,\n",
    "                            validation_split=0.3,\n",
    "                            verbose=0)\n",
    "\n",
    "    x_test_reversed = reverse_processing(x_test, x_scaler, x_test_target)\n",
    "\n",
    "    return model_mlp, x_test_reversed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_baseline_xgb(x_train, y_train, x_test, x_scaler, x_test_target):\n",
    "    model_xgb = xgb.XGBRegressor()\n",
    "    model_xgb.fit(x_train, y_train)\n",
    "\n",
    "    x_test_reversed = reverse_processing(x_test, x_scaler, x_test_target)\n",
    "\n",
    "    return model_xgb, x_test_reversed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make predictions on specific test subset using MLP and XGBoost models\n",
    "model_mlp_gk, x_test_reversed_gk = train_baseline_mlp(x_train_gk, y_train_gk, x_test_gk, x_scaler_gk, x_test_target_gk)\n",
    "predictions_mlp_gk = merge_reversed_data_with_predictions(model_mlp_gk, x_test_gk, y_test_gk, x_test_reversed_gk)\n",
    "\n",
    "model_mlp_def, x_test_reversed_def = train_baseline_mlp(x_train_def, y_train_def, x_test_def, x_scaler_def, x_test_target_def)\n",
    "predictions_mlp_def = merge_reversed_data_with_predictions(model_mlp_def, x_test_def, y_test_def, x_test_reversed_def)\n",
    "\n",
    "model_mlp_mid, x_test_reversed_mid = train_baseline_mlp(x_train_mid, y_train_mid, x_test_mid, x_scaler_mid, x_test_target_mid)\n",
    "predictions_mlp_mid = merge_reversed_data_with_predictions(model_mlp_mid, x_test_mid, y_test_mid, x_test_reversed_mid)\n",
    "\n",
    "model_mlp_fwd, x_test_reversed_fwd = train_baseline_mlp(x_train_fwd, y_train_fwd, x_test_fwd, x_scaler_fwd, x_test_target_fwd)\n",
    "predictions_mlp_fwd = merge_reversed_data_with_predictions(model_mlp_fwd, x_test_fwd, y_test_fwd, x_test_reversed_fwd)\n",
    "\n",
    "# concatenate predictions_mlp_gk with predictions_mlp_def, predictions_mlp_mid and predictions_mlp_fwd\n",
    "predictions_mlp_merged = pd.concat([predictions_mlp_gk, predictions_mlp_def, predictions_mlp_mid, predictions_mlp_fwd])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_xgb_gk, x_test_reversed_gk = train_baseline_xgb(x_train_gk, y_train_gk, x_test_gk, x_scaler_gk, x_test_target_gk)\n",
    "predictions_xgb_gk = merge_reversed_data_with_predictions(model_xgb_gk, x_test_gk, y_test_gk, x_test_reversed_gk)\n",
    "\n",
    "model_xgb_def, x_test_reversed_def = train_baseline_xgb(x_train_def, y_train_def, x_test_def, x_scaler_def, x_test_target_def)\n",
    "predictions_xgb_def = merge_reversed_data_with_predictions(model_xgb_def, x_test_def, y_test_def, x_test_reversed_def)\n",
    "\n",
    "model_xgb_mid, x_test_reversed_mid = train_baseline_xgb(x_train_mid, y_train_mid, x_test_mid, x_scaler_mid, x_test_target_mid)\n",
    "predictions_xgb_mid = merge_reversed_data_with_predictions(model_xgb_mid, x_test_mid, y_test_mid, x_test_reversed_mid)\n",
    "\n",
    "model_xgb_fwd, x_test_reversed_fwd = train_baseline_xgb(x_train_fwd, y_train_fwd, x_test_fwd, x_scaler_fwd, x_test_target_fwd)\n",
    "predictions_xgb_fwd = merge_reversed_data_with_predictions(model_xgb_fwd, x_test_fwd, y_test_fwd, x_test_reversed_fwd)\n",
    "\n",
    "# concatenate predictions_xgb_gk with predictions_xgb_def, predictions_xgb_mid and predictions_xgb_fwd\n",
    "predictions_xgb_merged = pd.concat([predictions_xgb_gk, predictions_xgb_def, predictions_xgb_mid, predictions_xgb_fwd])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get squad and evaluate it for both models\n",
    "results_mlp, selected_squad_points_mlp, real_player_average_points_mlp, season_gameweeks_mlp = evaluate_selected_squad_without_constraints(predictions_mlp_merged, test_subset_XL, 'mlp_model-no_constraints_SPEARATE_test_subset_XL')\n",
    "results_xgb, selected_squad_points_xgb, real_player_average_points_xgb, season_gameweeks_xgb = evaluate_selected_squad_without_constraints(predictions_xgb_merged, test_subset_XL, 'xgb_model-no_constraints_SPEARATE_test_subset_XL')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "X_axis = np.arange(len(season_gameweeks_mlp))\n",
    "\n",
    "plt.bar(X_axis - 0.3, selected_squad_points_xgb, 0.3, label = 'Selected squad points XGB')\n",
    "plt.bar(X_axis, real_player_average_points_mlp, 0.3, label = 'Real player average points')\n",
    "plt.bar(X_axis + 0.3, selected_squad_points_mlp, 0.3, label = 'Selected squad points MLP')\n",
    "\n",
    "plt.xticks(X_axis, season_gameweeks_mlp, rotation=30)\n",
    "plt.xlabel(\"Season and GW\")\n",
    "plt.ylabel(\"Points gained\")\n",
    "plt.title(\"Comparison of pts gained by squad selected by MLP model with points gained by squad selected by XGB model for big test subset\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MLP model sum of points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sum of points gained by selected squad:', sum(selected_squad_points_mlp))\n",
    "print('Sum of points gained by real players:', sum(real_player_average_points_mlp))\n",
    "print('Difference:', sum(selected_squad_points_mlp) - sum(real_player_average_points_mlp), 'pts')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGBoost model sum of points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sum of points gained by selected squad:', sum(selected_squad_points_xgb))\n",
    "print('Sum of points gained by real players:', sum(real_player_average_points_xgb))\n",
    "print('Difference:', sum(selected_squad_points_xgb) - sum(real_player_average_points_xgb), 'pts')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclustion #1\n",
    "MLP model seems to gain much more points than XGBoost model when 4 different models are trained with data separated by player position. It's strange for me, because I was expecting that XGB model will be better, when datasets are smaller. Comparing to the models trained with all data together, MLP model seems to have similar performance, but XGB model seems to be worse. Now I will try to train models separated on GK data and Field_players data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train two separate models (GK and Field_players)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data by position\n",
    "data_intermediate_path = os.path.dirname(os.getcwd()) + '\\\\data\\\\intermediate\\\\'\n",
    "\n",
    "data_gk = pd.read_csv(data_intermediate_path + 'separate/gk.csv')\n",
    "data_field = pd.read_csv(data_intermediate_path + 'separate/field.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rolling_columns_field = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity', 'goals_conceded', 'goals_scored',\n",
    "                       'ict_index', 'influence', 'minutes', 'selected', 'player_team_score', 'opponent_team_score',\n",
    "                       'threat', 'total_points', 'transfers_in', 'transfers_out', 'value', 'yellow_cards']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(x_train_gk, y_train_gk), (x_test_gk, y_test_gk), (x_train_target_gk, x_test_target_gk), x_scaler_gk = preprocess_seasons_data(data_gk, random_split=False, test_subset=test_subset_XL, rolling_features=True, rolling_columns=rolling_columns_gk, rolling_times=times, opponent_team_stats=True)\n",
    "\n",
    "(x_train_field, y_train_field), (x_test_field, y_test_field), (x_train_target_field, x_test_target_field), x_scaler_field = preprocess_seasons_data(data_field, random_split=False, test_subset=test_subset_XL, rolling_features=True, rolling_columns=rolling_columns_field, rolling_times=times, opponent_team_stats=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make predictions on specific test subset using MLP and XGBoost models\n",
    "model_mlp_gk, x_test_reversed_gk = train_baseline_mlp(x_train_gk, y_train_gk, x_test_gk, x_scaler_gk, x_test_target_gk)\n",
    "predictions_mlp_gk = merge_reversed_data_with_predictions(model_mlp_gk, x_test_gk, y_test_gk, x_test_reversed_gk)\n",
    "\n",
    "model_mlp_field, x_test_reversed_field = train_baseline_mlp(x_train_field, y_train_field, x_test_field, x_scaler_field, x_test_target_field)\n",
    "predictions_mlp_field = merge_reversed_data_with_predictions(model_mlp_field, x_test_field, y_test_field, x_test_reversed_field)\n",
    "\n",
    "# concatenate predictions_mlp_gk with predictions_mlp_def, predictions_mlp_mid and predictions_mlp_fwd\n",
    "predictions_mlp_merged_field = pd.concat([predictions_mlp_gk, predictions_mlp_field])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_xgb_gk, x_test_reversed_gk = train_baseline_xgb(x_train_gk, y_train_gk, x_test_gk, x_scaler_gk, x_test_target_gk)\n",
    "predictions_xgb_gk = merge_reversed_data_with_predictions(model_xgb_gk, x_test_gk, y_test_gk, x_test_reversed_gk)\n",
    "\n",
    "model_xgb_field, x_test_reversed_field = train_baseline_xgb(x_train_field, y_train_field, x_test_field, x_scaler_field, x_test_target_field)\n",
    "predictions_xgb_field = merge_reversed_data_with_predictions(model_xgb_field, x_test_field, y_test_field, x_test_reversed_field)\n",
    "\n",
    "# concatenate predictions_xgb_gk with predictions_xgb_def, predictions_xgb_mid and predictions_xgb_fwd\n",
    "predictions_xgb_merged_field = pd.concat([predictions_xgb_gk, predictions_xgb_field])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get squad and evaluate it for both models\n",
    "results_mlp_field, selected_squad_points_mlp_field, real_player_average_points_mlp_field, season_gameweeks_mlp_field = evaluate_selected_squad_without_constraints(predictions_mlp_merged_field, test_subset_XL, 'mlp_model-no_constraints_FIELD_test_subset_XL')\n",
    "results_xgb_field, selected_squad_points_xgb_field, real_player_average_points_xgb_field, season_gameweeks_xgb_field = evaluate_selected_squad_without_constraints(predictions_xgb_merged_field, test_subset_XL, 'xgb_model-no_constraints_FIELD_test_subset_XL')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "X_axis = np.arange(len(season_gameweeks_mlp))\n",
    "\n",
    "plt.bar(X_axis - 0.3, selected_squad_points_xgb_field, 0.3, label = 'Selected squad points XGB')\n",
    "plt.bar(X_axis, real_player_average_points_mlp_field, 0.3, label = 'Real player average points')\n",
    "plt.bar(X_axis + 0.3, selected_squad_points_mlp_field, 0.3, label = 'Selected squad points MLP')\n",
    "\n",
    "plt.xticks(X_axis, season_gameweeks_mlp, rotation=30)\n",
    "plt.xlabel(\"Season and GW\")\n",
    "plt.ylabel(\"Points gained\")\n",
    "plt.title(\"Comparison of pts gained by squad selected by MLP model with points gained by squad selected by XGB model for big test subset\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MLP model sum of points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sum of points gained by selected squad:', sum(selected_squad_points_mlp_field))\n",
    "print('Sum of points gained by real players:', sum(real_player_average_points_mlp))\n",
    "print('Difference:', sum(selected_squad_points_mlp_field) - sum(real_player_average_points_mlp), 'pts')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGBoost model sum of points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Sum of points gained by selected squad:', sum(selected_squad_points_xgb_field))\n",
    "print('Sum of points gained by real players:', sum(real_player_average_points_xgb))\n",
    "print('Difference:', sum(selected_squad_points_xgb_field) - sum(real_player_average_points_xgb), 'pts')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_mlp_field"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}